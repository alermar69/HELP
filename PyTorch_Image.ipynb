{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "PyTorch_Image.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KVLEvGh6gvf3"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OUmFy7hFgvf5"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as tfs\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R90erZBhN1y"
      },
      "source": [
        "## База"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-KB8B2RhZNQ"
      },
      "source": [
        "Свёрточные нейросети (обыкновенные, есть и намного более продвинутые) почти всегда строятся по следующему правилу:  \n",
        "\n",
        "`INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC`  \n",
        "\n",
        "то есть:  \n",
        "\n",
        "1). ***Входной слой*** (batch картинок `HxWxC`)  \n",
        "\n",
        "2). $M$ блоков (M $\\ge$ 0) из свёрток и pooling-ов, причём именно в том порядке, как в формуле выше. Все эти $M$ блоков вместе называют ***feature extractor*** свёрточной нейросети, потому что эта часть сети отвечает непосредственно за формирование новых, более сложных признаков, поверх тех, которые подаются (то есть, по аналогии с MLP, мы опять же переходим к новому признаковому пространству, однако здесь оно строится сложнее, чтем в обычных многослойных сетях, поскольку используется операция свёртки)  \n",
        "\n",
        "3). $K$ штук FullyConnected-слоёв (с активациями). Эту часть из $K$ FC-слоёв называют ***classificator***, поскольку эти слои отвечают непосредственно за предсказание нужно класса (сейчас рассматривается задача классификации изображений)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIh0bUCoh4RH"
      },
      "source": [
        "В свёрточной нейросети можно настроить следующие вещи:  \n",
        "\n",
        "- (в каждом ConvLayer) **размер фильтров (окна свёртки)** (`kernel_size`)\n",
        "- (в каждом ConvLayer) **количество фильтров** (`out_channels`)  \n",
        "- (в каждом ConvLayer) размер **шага окна свёртки (stride)** (`stride`)  \n",
        "- (в каждом ConvLayer) **тип padding'а** (`padding`)  \n",
        "\n",
        "\n",
        "- (в каждом PoolLayer) **размер окна pooling'a** (`kernel_size`)  \n",
        "- (в каждом PoolLayer) **шаг окна pooling'а** (`stride`)  \n",
        "- (в каждом PoolLayer) **тип pooling'а** (`pool_type`)  \n",
        "- (в каждом PoolLayer) **тип padding'а** (`padding`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ47M6fHprBr"
      },
      "source": [
        "### Convolution (свёртка)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAJ3c5OipxwB"
      },
      "source": [
        "То есть мы берём фильтр размера FxF, умножаем его на область изображения размером FxF поэлементно, складываем получившиеся поэлемнетные произведения и записываем это число в результирующий тензор.\n",
        "\n",
        "За исключением архитектур типа MobileNet, третья размерность фильтра всегда свопадает с третьей размерностью входного тензора. Если картинка размера HxWx3, то фильтр будет иметь размер FxFx3, и поэлементное произведение будет производиться по всему объёму."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfhTSUMop8GJ"
      },
      "source": [
        "Два важных параметра операции свертки:\n",
        "\n",
        "$stride$ -- это размер шага окна свёртка по осям x и y (обычно совпадают, но вполне могут быть и разными).\n",
        "\n",
        "$padding$ -- это окружение картинки по краям нулями (или чем-то другим) для того, чтобы придать изображению после свёртки нужный размер (пэддинг делается до свёртки)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfv3X6QVqgUY"
      },
      "source": [
        "nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mfg2WSUqjQ4"
      },
      "source": [
        "### Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHpbfEIvqqkI"
      },
      "source": [
        "Pooling (пулинг) -- операция, нужная для уменьшения размерности по ширине и по высоте. Можно брать очень много операций в качестве пулинга, например, минимум из элементов, максимум, среднее, сумму и т.д."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6Wvc55yqubX"
      },
      "source": [
        "Обычно используется max- и avg-pooling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2_Zo_vPrK-H"
      },
      "source": [
        "Если на вход подаётся изображение с несколькими каналами, то пулинг берётся по каналам, то есть если это цветная картинка HxWxC, и мы применяем к ней pooling 2x2, то получим на выходе (H // 2) x (W // 2) x C"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUFtKqMlraP2"
      },
      "source": [
        "nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "F.max_pool2d(F.relu(self.conv1(x)), (2, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "vuKwmPfYgvf6"
      },
      "source": [
        "## Базовые примеры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDD_cje-o680"
      },
      "source": [
        "### MyModule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xIR6RodpCM7"
      },
      "source": [
        "class MyConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора предка\n",
        "        super().__init__()\n",
        "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 1),\n",
        "        # которую будем подавать в сеть, больше ничего\n",
        "        # про входящие картинки знать не нужно\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.fc1 = nn.Linear(6 * 6 * 128, 128)  # !!!\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #(32,32)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        #(14,14)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #(6,6)\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 6 * 6 * 128)  # !!!\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oukpwd3apZ5i"
      },
      "source": [
        "**Важное примечание:** Вы можете заметить, что в строчках с `#!!!` есть не очень понятный сходу 4 `*` 4 `*` 16. Это -- размерность картинки перед FC-слоями (H x W x C), тут её приходиться высчитывать вручную (в Keras, например, `.Flatten()` всё делает за Вас). Однако есть один *лайфхак* -- просто сделайте в `forward()` `print(x.shape)` (закомментированная строка). Вы увидите размер `(batch_size, C, H, W)` -- нужно перемножить все, кроме первого (batch_size), это и будет первая размерность `Linear()`, и именно в C * H * W нужно \"развернуть\" x перед подачей в `Linear()`.  \n",
        "\n",
        "То есть нужно будет запустить цикл с обучением первый раз с `print()` и сделать после него `break`, посчитать размер, вписать его в нужные места и стереть `print()` и `break`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "TqPPr09Mgvf7"
      },
      "source": [
        "### MNIST (модель LeNet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EONk6BcGgvf7"
      },
      "source": [
        "import os\n",
        "from catalyst.contrib.datasets import MNIST\n",
        "\n",
        "train_dataset = MNIST(root=os.getcwd(), train=True, download=True)\n",
        "val_dataset = MNIST(root=os.getcwd(), train=False)\n",
        "train_dataloader =  DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "valid_dataloader =  DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = LeNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "loaders = {\"train\": train_dataloader, \"valid\": valid_dataloader}\n",
        "\n",
        "max_epochs = 10\n",
        "accuracy = {\"train\": [], \"valid\": []}\n",
        "for epoch in range(max_epochs):\n",
        "    epoch_correct = 0\n",
        "    epoch_all = 0\n",
        "    utils.set_global_seed(42+epoch)\n",
        "    for k, dataloader in loaders.items():\n",
        "        for x_batch, y_batch in dataloader:\n",
        "            if k == \"train\":\n",
        "                model.train()\n",
        "                optimizer.zero_grad()\n",
        "                outp = model(x_batch.type(torch.float32).unsqueeze(1))\n",
        "            else:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    outp = model(x_batch.type(torch.float32).unsqueeze(1))\n",
        "            preds = outp.argmax(-1)\n",
        "            correct = (y_batch == preds).sum()\n",
        "            all =  x_batch.shape[0]\n",
        "            epoch_correct += correct.item()\n",
        "            epoch_all += all\n",
        "            if k == \"train\":\n",
        "                loss = criterion(outp, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        if k == \"train\":\n",
        "            print(f\"Epoch: {epoch+1}\")\n",
        "        print(f\"Loader: {k}. Accuracy: {epoch_correct/epoch_all}\")\n",
        "        accuracy[k].append(epoch_correct/epoch_all)\n",
        "\n",
        "lenet_accuracy = accuracy[\"valid\"]\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "plt.title(\"Valid accuracy\")\n",
        "# plt.plot(range(max_epochs), relu_accuracy, label=\"ReLU activation\", linewidth=2)\n",
        "# plt.plot(range(max_epochs), leaky_relu_accuracy, label=\" activation\", linewidth=2)\n",
        "# plt.plot(range(max_epochs), elu_accuracy, label=\"ELU activation\", linewidth=2)\n",
        "plt.plot(range(max_epochs), lenet_accuracy, label=\"LeNet\", linewidth=2)\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lTTD26mwgvf9"
      },
      "source": [
        "### CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hf52ONThgvf9"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PFdga2z0gvf9"
      },
      "source": [
        "class MyConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора предка\n",
        "        super().__init__()\n",
        "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 1),\n",
        "        # которую будем подавать в сеть, больше ничего\n",
        "        # про входящие картинки знать не нужно\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.fc1 = nn.Linear(6 * 6 * 128, 128)  # !!!\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #(32,32)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        #(14,14)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #(6,6)\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 6 * 6 * 128)  # !!!\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OIFph-Xlgvf_"
      },
      "source": [
        "# пример взят из официального туториала:\n",
        "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "\n",
        "net = MyConvNet().to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "# итерируемся\n",
        "for epoch in tqdm_notebook(range(10)):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, batch in enumerate(tqdm_notebook(trainloader)):\n",
        "        # так получаем текущий батч\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        # обнуляем веса\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        y_pred = net(X_batch.to(device))\n",
        "        loss = loss_fn(y_pred, y_batch.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выведем текущий loss\n",
        "        running_loss += loss.item()\n",
        "        # выводем качество каждые 2000 батчей\n",
        "        if i % 2000 == 1999:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Обучение закончено')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Pj8fwfPtgvf_"
      },
      "source": [
        "# Посмотрим на accuracy на тестовом датасете:\n",
        "\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        y_pred = net(images.to(device))#.view(4, -1))\n",
        "        _, predicted = torch.max(y_pred, 1)\n",
        "        c = (predicted.cpu().detach() == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}