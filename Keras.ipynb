{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkGCsFtv3BYRo5gswQvmuR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alermar69/HELP/blob/master/Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6kvoQT-Z-8_"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDz5ucl-aEzM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.models import Sequential #НС прямого распространения\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization #Основные слои\n",
        "#Базовые слои для счёрточных сетей\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, Adadelta # оптимизаторы\n",
        "from tensorflow.keras import utils #Утилиты для to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab # Модуль для построения графиков\n",
        "from mpl_toolkits.mplot3d import Axes3D # Модуль для трехмерной графики\n",
        "from google.colab import files #Для загрузки своей картинки\n",
        "from tensorflow.keras.preprocessing import image #Для отрисовки изображения\n",
        "from PIL import Image #Отрисовка изображений\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator # работа с изображениями\n",
        "\n",
        "import random #Для генерации случайных чисел \n",
        "import math # Для округления\n",
        "import os #Для работы с файлами \n",
        "from google.colab import drive # подключем диск\n",
        "from google.colab import files #Для загрузки своей картинки\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.datasets import cifar100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGK_PPFeqwFc"
      },
      "source": [
        "## Base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uF4nMtRbrye"
      },
      "source": [
        "### MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdgwhdIIa0O6"
      },
      "source": [
        "(x_train_org, y_train_org), (x_test_org, y_test_org) = mnist.load_data() #Загрузка данных Mnist\n",
        "plt.imshow(5, cmap='viridis') #Отрисовка картинки\n",
        "\n",
        "#Меняем формат входных картинок с 28х28 на 784х1\n",
        "x_train = x_train_org.reshape(60000, 784)\n",
        "x_test = x_test_org.reshape(10000, 784)\n",
        "\n",
        "#Нормализуем входные картинки\n",
        "x_train = x_train.astype('float32') # преобразовываем x_train в тип float (цифры с плавающей точкой)\n",
        "x_train = x_train / 255 # делим на 255, чтобы диапазон был от 0 до 1\n",
        "x_test = x_test.astype('float32')\n",
        "x_test = x_test / 255\n",
        "\n",
        "# Преобразуем ответы в формат one_hot_encoding\n",
        "y_train = utils.to_categorical(y_train_org, 10)\n",
        "y_test = utils.to_categorical(y_test_org, 10)\n",
        "\n",
        "# Создание нейронной сети\n",
        "model = Sequential() # Создаём сеть прямого распространения\n",
        "model.add(Dense(800, input_dim=784, activation=\"relu\")) # Добавляем полносвязный слой на 800 нейронов с relu-активацией\n",
        "model.add(Dense(400, activation=\"relu\")) # Добавляем полносвязный слой на 400 нейронов с relu-активацией\n",
        "model.add(Dense(10, activation=\"softmax\")) # Добавляем полносвязный слой на 10 нейронов с softmax-активацией\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) # Компилируем модель\n",
        "print(model.summary()) #Вывод структуры модели \n",
        "\n",
        "# Обучение нейронной сети\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=15, verbose=1, validation_split=0.2)\n",
        "\n",
        "model.save_weights('model.h5')\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "# Распознавание рукописных цифр\n",
        "\n",
        "#Выбираем нужную картинку из тестовой выборки\n",
        "x = x_test[5]\n",
        "#Добавляем одну размерность в конце, чтобы нейронка могла распознать пример\n",
        "#Потому что нейронка принимает именно массив примеров для распознавания\n",
        "#Мы делаем массив из одного примера\n",
        "x = np.expand_dims(x, axis=0)\n",
        "prediction = model.predict(x) #Распознаём наш пример\n",
        "prediction = np.argmax(prediction) # Получаем индекс самого большого элемента (это итоговая цифра, которую распознала сеть)\n",
        "\n",
        "\n",
        "# Загружаем картинку сделанную в графическом редакторе\n",
        "example = image.load_img('/content/4_.png', target_size=(28, 28), color_mode = 'grayscale') \n",
        "# Нормализуем данные\n",
        "example = image.img_to_array(example) # преобразуем изображение в numpy-массив\n",
        "example = example.reshape(1,784)\n",
        "example = np.where(example > 100, 255, example) # убираем шум\n",
        "example = example.astype('float32')\n",
        "example = 1- example/255 # Делаем инверсию, чтобы было не черное на белом, а белая цифра на черном фоне\n",
        "#Распознаём наш пример\n",
        "pred_example = model_sample.predict(example) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtBtSnlhlNqe"
      },
      "source": [
        "### Создание модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbBpwWh-lRoX"
      },
      "source": [
        "#Функция пересоздаёт пустую сеть\n",
        "def createModel():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "  model.add(Dropout(0.2)) #20% нейронов будут выключены\n",
        "  model.add(BatchNormalization()) #Добавляем слой пакетной нормализации\n",
        "  model.add(Dense(25,  activation=\"tanh\"))\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "  \n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=0.006), metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60V9UamIg07b"
      },
      "source": [
        "### Варианты создания проверочной выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z46DI_pvg4XU"
      },
      "source": [
        "#validation_split\n",
        "model.fit(x_train, y_train, batch_size=200, epochs=3, verbose=1,\n",
        "          validation_split=0.2) #Указываем 20% случайных примеров для проверочной выборки\n",
        "\n",
        "#validation_data\n",
        "n_val = 10000 #Указываем 10.000 примеров в проверочную выборку\n",
        "x_len = x_train.shape[0] #Запоминаем размер всей выборки целиком\n",
        "\n",
        "model.fit(x_train[:x_len-n_val], #Берём все до индекса 60.000 - 10.000 = 50.000\n",
        "          y_train[:x_len-n_val], \n",
        "          batch_size=200, epochs=3,\n",
        "          #Прямо указываем данные для проверочной выборки\n",
        "          #Берём от индекса 50.000 до конца = 10.000 примеров\n",
        "          validation_data=(x_train[x_len-n_val:], y_train[x_len-n_val:]))\n",
        "\n",
        "#sklearn train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_new, x_val, y_train_new, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
        "model.fit(x_train_new, y_train_new, batch_size=200, epochs=3,\n",
        "          validation_data=(x_val, y_val)) #Пряму указываем проверочную выборку\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3P21H_MjPB7"
      },
      "source": [
        "### Проверяем качество обучения на тестовом наборе данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGo1RLaBjSDM"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "#scores состоит из двух знанчений\n",
        "#scores[0] - loss сети на тестовой выборке\n",
        "#scores[1] - процент правильно распознанных примеров на тестовой выборке"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJc9AbfQjyuq"
      },
      "source": [
        "### Визуализация качества обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyNIv8Grj0Kq"
      },
      "source": [
        "history = model.fit(x_train,y_train,batch_size=200, epochs=20, validation_split=0.2, verbose=1)\n",
        "\n",
        "#Ключи в структуре history\n",
        "print(history.history.keys()) #dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n",
        "\n",
        "#Значения loss на обучающей выборке по эпохам\n",
        "history.history['loss']\n",
        "\n",
        "#Значения точности распознавания на проверочной выборке по эпохам\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "#Выводим графики точности\n",
        "plt.plot(history.history['acc'], label='Доля верных ответов на обучающем наборе')\n",
        "plt.plot(history.history['val_acc'], label='Доля верных ответов на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "plt.legend()\n",
        "\n",
        "#Выводим графики ошибки\n",
        "plt.plot(history.history['loss'], label='Ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'], label='Ошибка на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Ошибка')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DisWI3_q-5P"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5U0Y-hFrClp"
      },
      "source": [
        "batch_size = 128 \n",
        "\n",
        "model = Sequential()\n",
        "model.add(BatchNormalization(input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(x_train, y_train, verbose=1,\n",
        "                    batch_size=batch_size, epochs=15,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Доля верных ответов на обучающем наборе')\n",
        "plt.plot(history.history['val_accuracy'], label='Доля верных ответов на проверочном наборе')\n",
        "plt.xlabel('Эпоха обучения')\n",
        "plt.ylabel('Доля верных ответов')\n",
        "plt.legend()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}