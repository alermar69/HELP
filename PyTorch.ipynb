{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "PyTorch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alermar69/HELP/blob/master/PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIBq2GLIqtRG"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7h_SuE-qyBW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as tfs\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUXenYA1q16j"
      },
      "source": [
        "## Base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCT6ioLMq8q6"
      },
      "source": [
        "### Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqXiqTbJq4Vb"
      },
      "source": [
        "torch.HalfTensor      # 16 бит, floating point\n",
        "torch.FloatTensor     # 32 бита, floating point\n",
        "torch.DoubleTensor    # 64 бита, floating point\n",
        "\n",
        "torch.ShortTensor     # 16 бит, integer, signed\n",
        "torch.IntTensor       # 32 бита, integer, signed\n",
        "torch.LongTensor      # 64 бита, integer, signed\n",
        "\n",
        "torch.CharTensor      # 8 бит, integer, signed\n",
        "torch.ByteTensor      # 8 бит, integer, unsigned\n",
        "\n",
        "torch.FloatTensor([[1,2,3], [4,5,6]])\n",
        "torch.FloatTensor(2,3,4)\n",
        "torch.FloatTensor(3, 2, 4).zero_()\n",
        "\n",
        "a.type_as(torch.IntTensor())\n",
        "\n",
        "# np.reshape() == torch.view()\n",
        "b.view(3, 2)\n",
        "b.view(-1)\n",
        "\n",
        "a.sum(dim=0)\n",
        "a.sum(1)\n",
        "\n",
        "a.t()\n",
        "\n",
        "# вектор на вектор\n",
        "a.dot(b)\n",
        "a @ b\n",
        "\n",
        "# матрица на матрицу\n",
        "a.mm(b)\n",
        "a @ b\n",
        "\n",
        "# матрица на вектор\n",
        "a.mv(b)\n",
        "a @ b\n",
        "\n",
        "torch.from_numpy(a)\n",
        "x = a.numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-tGXm-iu3rH"
      },
      "source": [
        "### Cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi5saqVQu6EZ"
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
        "\n",
        "x.is_cuda\n",
        "device = torch.device(\"cuda:0\")\n",
        "x = x.to(device)\n",
        "c = a.cuda().mul(b.cuda()).cpu()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')          # CUDA-device object\n",
        "    y = torch.ones_like(x, device=device)  # create a tensor on GPU\n",
        "    x = x.to(device)                       # or just `.to(\"cuda\")`\n",
        "    z = x + y\n",
        "    print(z.to(\"cpu\", torch.double))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgHs0TAkvdF3"
      },
      "source": [
        "### Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c7KrEW5veSY"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "N, D_in, H, D_out = 64, 3, 3, 10\n",
        "\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "y_pred = (x @ w1).clamp(min=0).mm(w2)\n",
        "\n",
        "loss = (y_pred - y).pow(2).sum()\n",
        "# calculate the gradients\n",
        "loss.backward()\n",
        "\n",
        "w1.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMQz9o5ZwiVj"
      },
      "source": [
        "### Подготовка набора данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBwv3ocmv8UV"
      },
      "source": [
        "#### Compose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "809-sKKAv_bW"
      },
      "source": [
        "import torchvision.transforms as tfs\n",
        "\n",
        "data_tfs = tfs.Compose([\n",
        "  tfs.ToTensor(),\n",
        "  tfs.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "root = './'\n",
        "train = MNIST(root, train=True,  transform=data_tfs, download=True)\n",
        "test  = MNIST(root, train=False, transform=data_tfs, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0uhh5Y0mdXQ"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "root = './'\n",
        "train = torchvision.datasets.CIFAR10(root, train=True,  transform=transform, download=True)\n",
        "test  = torchvision.datasets.CIFAR10(root, train=False, transform=transform, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f3CdTGpwTbs"
      },
      "source": [
        "#### DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn59qH6swU6l"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "x_batch, y_batch = next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIJvUt_COQ0Q"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlOGw7rq7Tqu"
      },
      "source": [
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ttsy_FciTjA"
      },
      "source": [
        "# Сами данные лежат в полях trainloader.dataset.train_data:\n",
        "trainloader.dataset.train_data.shape\n",
        "\n",
        "#Выведем первую картинку:\n",
        "numpy_img = trainloader.dataset.train_data[0].numpy()\n",
        "plt.imshow(numpy_img, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TTYU1cZjIzf"
      },
      "source": [
        "# Как итерироваться по данным с помощью loader'а\n",
        "for data in trainloader:\n",
        "    print(data)\n",
        "    break\n",
        "# То есть мы имеем дело с кусочками данных размера batch_size (в данном случае = 4),\n",
        "# причём в каждом батче есть как объекты, так и ответы на них (то есть и X, и y)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzGCg_0AxnIq"
      },
      "source": [
        "### Model and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAXlNKU2rvPY"
      },
      "source": [
        "#### Цикл обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnw0FNgruNzT"
      },
      "source": [
        "код ниже подойдет для 90% задач"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJNFUUpUruSq"
      },
      "source": [
        "for epoch in range(max_epochs):  # <--------------- итерируемся по датасету несколько раз\n",
        "    for k, dataloader in loaders.items():  # <----- несколько dataloader для train / valid / test\n",
        "        for x_batch, y_batch in dataloader:  # <--- итерируемся по датасету. Так как мы используем SGD а не GD, то берем батчи заданного размера\n",
        "            if k == \"train\":\n",
        "                model.train()  # <------------------ переводим модель в режим train\n",
        "                optimizer.zero_grad()  # <--------- обнуляем градиенты модели\n",
        "                outp = model(x_batch)\n",
        "                loss = criterion(outp, y_batch) # <-считаем \"лосс\" для логистической регрессии\n",
        "                loss.backward()  # <--------------- считаем градиенты\n",
        "                optimizer.step()  # <-------------- делаем шаг градиентного спуска\n",
        "            else:  # <----------------------------- test/eval\n",
        "                model.eval()  # <------------------ переводим модель в режим eval\n",
        "                with torch.no_grad():  # <--------- НЕ считаем градиенты\n",
        "                    outp = model(x_batch)  # <------------- получаем \"логиты\" из модели\n",
        "            count_metrics(outp, y_batch)  # <-------------- считаем метрики"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwjkDNoLWAFN"
      },
      "source": [
        "#### В ручную"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgnUAVE9xoyL"
      },
      "source": [
        "features = 784\n",
        "classes = 10\n",
        "epochs = 3\n",
        "lr=1e-2\n",
        "history = []\n",
        "\n",
        "W = torch.FloatTensor(features, classes).uniform_(-1, 1) / features**0.5\n",
        "\n",
        "for i in range(epochs):\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    x_batch = x_batch.reshape(x_batch.shape[0], -1)\n",
        "\n",
        "    logits = x_batch @ W\n",
        "    probabilities = torch.exp(logits) / torch.exp(logits).sum(dim=1, keepdims=True)\n",
        "    \n",
        "    loss = -torch.log(probabilities[range(batch_size), y_batch]).mean()\n",
        "    history.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    grad = W.grad\n",
        "    with torch.no_grad():\n",
        "      W -= lr * grad\n",
        "    W.grad.zero_()\n",
        "\n",
        "  print(f'{i+1},\\t loss: {history[-1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mni6AQ1UIJ_"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc = 0\n",
        "batches = 0\n",
        "\n",
        "for x_batch, y_batch in test_loader:\n",
        "  batches += 1\n",
        "  x_batch = x_batch.view(x_batch.shape[0], -1)\n",
        "  y_batch = y_batch\n",
        "\n",
        "  preds = torch.argmax(x_batch @ W, dim=1)\n",
        "  acc += (preds==y_batch).cpu().numpy().mean()\n",
        "\n",
        "print(f'Test accuracy {acc / batches:.3}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD61Babfu3rp"
      },
      "source": [
        "Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5T0Feonu9Zx"
      },
      "source": [
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(in_features, out_features, requires_grad=True))\n",
        "        self.bias = bias\n",
        "        if bias:\n",
        "            self.bias_term = nn.Parameter(torch.randn(1, out_features, requires_grad=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x =  x @ self.weights\n",
        "        if self.bias:\n",
        "            x +=  self.bias_term\n",
        "        return x\n",
        "\n",
        "X, y = make_moons(n_samples=10000, random_state=42, noise=0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)\n",
        "\n",
        "X_train_t =  torch.from_numpy(X_train).type_as(torch.FloatTensor())\n",
        "y_train_t =  torch.from_numpy(y_train).type_as(torch.FloatTensor())\n",
        "X_val_t =  torch.from_numpy(X_val).type_as(torch.FloatTensor())\n",
        "y_val_t =  torch.from_numpy(y_val).type_as(torch.FloatTensor())\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=128)\n",
        "\n",
        "utils.set_global_seed(42)\n",
        "linear_regression = LinearRegression(2, 1)\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(linear_regression.parameters(), lr=0.05)\n",
        "\n",
        "tol = 1e-3\n",
        "losses = []\n",
        "max_epochs = 100\n",
        "prev_weights = torch.zeros_like(linear_regression.weights)\n",
        "stop_it = False\n",
        "for epoch in range(max_epochs):\n",
        "    utils.set_global_seed(42 + epoch)\n",
        "    for it, (X_batch, y_batch) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outp =  linear_regression(X_batch)\n",
        "        prob = F.sigmoid(outp)\n",
        "        loss =  -torch.log(torch.cat((prob[y_batch == 1], 1-prob[y_batch == 0]), 0)).mean()\n",
        "        loss.backward()\n",
        "        losses.append(loss.detach().flatten()[0])\n",
        "        optimizer.step()\n",
        "        probabilities =  prob\n",
        "        preds = (probabilities>0.5).type(torch.long)\n",
        "        batch_acc = (preds.flatten() == y_batch).type(torch.float32).sum()/y_batch.size(0)\n",
        "        if it % 500000 == 0:\n",
        "            print(f\"Iteration: {it + epoch*len(train_dataset)}\\nBatch accuracy: {batch_acc}\")\n",
        "        current_weights = linear_regression.weights.detach().clone()\n",
        "        if (prev_weights - current_weights).abs().max() < tol:\n",
        "            print(f\"\\nIteration: {it + epoch*len(train_dataset)}.Convergence. Stopping iterations.\")\n",
        "            stop_it = True\n",
        "            break\n",
        "        prev_weights = current_weights\n",
        "    if stop_it:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmeVrWr7WT6U"
      },
      "source": [
        "#### nn.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEfS6aJNWkKt"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPbym84yWriF"
      },
      "source": [
        "model = nn.Sequential(\n",
        "  nn.Linear(features, 64),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(64, classes)\n",
        ")\n",
        "\n",
        "summary(model, (features,), batch_size=228)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # (logsoftmax + negative likelihood) in its core, applied to logits\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
        "\n",
        "epochs = 3\n",
        "history = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    x_batch = x_batch.view(x_batch.shape[0], -1).to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "\n",
        "    loss = criterion(logits, y_batch)\n",
        "    history.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'{i+1},\\t loss: {history[-1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs5G1jghj-Ot"
      },
      "source": [
        "#### Functional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfijZRrOkQlM"
      },
      "source": [
        "import torch.nn.functional as F  # Functional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqOZCvxwkVSs"
      },
      "source": [
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора предка\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 1),\n",
        "        # которую будем подавать в сеть, больше ничего\n",
        "        # про входящие картинки знать не нужно\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 16, 120)  # !!!\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 4 * 4 * 16)  # !!!\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHEkPdSEkmIs"
      },
      "source": [
        "**Важное примечание:** Вы можете заметить, что в строчках с `#!!!` есть не очень понятный сходу 4 `*` 4 `*` 16. Это -- размерность картинки перед FC-слоями (H x W x C), тут её приходиться высчитывать вручную (в Keras, например, `.Flatten()` всё делает за Вас). Однако есть один *лайфхак* -- просто сделайте в `forward()` `print(x.shape)` (закомментированная строка). Вы увидите размер `(batch_size, C, H, W)` -- нужно перемножить все, кроме первого (batch_size), это и будет первая размерность `Linear()`, и именно в C * H * W нужно \"развернуть\" x перед подачей в `Linear()`.  \n",
        "\n",
        "То есть нужно будет запустить цикл с обучением первый раз с `print()` и сделать после него `break`, посчитать размер, вписать его в нужные места и стереть `print()` и `break`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uwjgZxYk0rK"
      },
      "source": [
        "# Код обучения слоя:\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "# объявляем сеть\n",
        "net = SimpleConvNet().to(device)\n",
        "\n",
        "# выбираем функцию потерь\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# выбираем алгоритм оптимизации и learning_rate\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "losses = []\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "# итерируемся\n",
        "for epoch in tqdm_notebook(range(2)):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, batch in enumerate(tqdm_notebook(trainloader)):\n",
        "        # так получаем текущий батч\n",
        "        X_batch, y_batch = batch\n",
        "        \n",
        "        # обнуляем веса\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        y_pred = net(X_batch.to(device))\n",
        "        loss = loss_fn(y_pred, y_batch.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выведем текущий loss\n",
        "        running_loss += loss.item()\n",
        "        # выведем качество каждые 2000 батчей\n",
        "        if i % 2000 == 1999:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            losses.append(running_loss)\n",
        "            running_loss = 0.0\n",
        "\n",
        "    ax.clear()\n",
        "    ax.plot(np.arange(len(losses)), losses)\n",
        "    plt.show()\n",
        "\n",
        "print('Обучение закончено')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qvzJ37FlqcS"
      },
      "source": [
        "# Протестируем на всём тестовом датасете, используя метрику accuracy_score:\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        y_pred = net(images.to(device))\n",
        "        _, predicted = torch.max(y_pred, 1)\n",
        "        \n",
        "        c = (predicted.cpu().detach() == labels)\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWOtL4ZcipV1"
      },
      "source": [
        "#### MyModule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ4RI2xbnu01"
      },
      "source": [
        "Что такое модуль и как он устроен? Во-первых, модуль это такой строительный блок для нейронок, с помощью модуля можно задать любую дифференциируемую по своему параметру функцию. Применяются модули так же, как и обычные функции с синтаксисом\n",
        "> module_instance(var1, var2)\n",
        "\n",
        "При этом внутри вызывается функция forward с теми же аргументами, а ее выход возвращается как результат вызова модуля. Зачем же нужно так странно оборачивать обычные функции в модули? \n",
        "\n",
        "* Это позволяет очень удобно следить за параметрами, которые надо изменять. Когда мы хоти получить все параметры можно просто рекурсивно пройтись по всем полям модели, посмотреть, какие из ни параметры сами по себе, а какие являются модулями и содрежат параметры внутри, а потом все это собрать. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHISAoqrn_3c"
      },
      "source": [
        "_По этой причине если вы используете внутри своего модуля какие-то еще модули их надо класть просто в поле класса, если это единичный модуль, и в класс **nn.ModuleList** или **nn.ModuleDict**, если у вас список или словарь используемых модулей. Если же в модели у вас есть како-то собственный вес, то недостаточно положить тензор в поле класса, его надо обернуть в **nn.Parameter, nn.ParameterList** или **nn.ParameterDict** в зависимотси от того, что именно у вас._\n",
        "\n",
        "* Такая организация позволяет достаточно безболезненно расширять PyTorch и писать для него свои функции, которые нельзя выразить композицией уже существующих. Пригождается это редко, поэтому сегодня мы не будем писать свое расширение.\n",
        "\n",
        "* Код, разделенный на модули, это просто красиво."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgRzlKJtiuXq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class MyModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear_layers = nn.ModuleList([nn.Linear(D_in, H), nn.Linear(H, D_out)])\n",
        "        self.my_useless_bias = nn.Parameter(torch.ones(1, H, requires_grad=True))\n",
        "        self.more_of_my_useless_biases = nn.ParameterList([\n",
        "            nn.Parameter(torch.ones(1, H, requires_grad=True)),\n",
        "            nn.Parameter(torch.ones(1, H, requires_grad=True)),\n",
        "            nn.Parameter(torch.ones(1, H, requires_grad=True))\n",
        "        ])\n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.linear_layers[0](X))\n",
        "        X += self.my_useless_bias\n",
        "        for b in self.more_of_my_useless_biases:\n",
        "            X += b\n",
        "        return F.softmax(self.linear_layers[1](X))\n",
        "    \n",
        "model = MyModule()\n",
        "list(model.parameters())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j5k6ADrnHOv"
      },
      "source": [
        "class MyConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора предка\n",
        "        super().__init__()\n",
        "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 1),\n",
        "        # которую будем подавать в сеть, больше ничего\n",
        "        # про входящие картинки знать не нужно\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.fc1 = nn.Linear(6 * 6 * 128, 128)  # !!!\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #(32,32)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        #(14,14)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #(6,6)\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 6 * 6 * 128)  # !!!\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}