{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "PyTorch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alermar69/HELP/blob/master/PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIBq2GLIqtRG"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7h_SuE-qyBW"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import torchvision.transforms as tfs\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "import torch.nn as nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKwU-HYCxrSq"
      },
      "source": [
        "## Код обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej6vlkIvwjG1"
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl, lr_sched=None):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    valid_accuracies = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        loss_sum = 0\n",
        "        for xb, yb in tqdm(train_dl):\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            loss_sum += loss.item()\n",
        "            \n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        train_losses.append(loss_sum / len(train_dl))\n",
        "\n",
        "        model.eval()\n",
        "        loss_sum = 0\n",
        "        correct = 0\n",
        "        num = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in valid_dl:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                probs = model(xb)\n",
        "                loss_sum += loss_func(probs, yb).item()\n",
        "                \n",
        "                _, preds = torch.max(probs, axis=-1)\n",
        "                correct += (preds == yb).sum().item()\n",
        "                num += len(xb)\n",
        "                \n",
        "        val_losses.append(loss_sum / len(valid_dl))\n",
        "        valid_accuracies.append(correct / num)\n",
        "\n",
        "        lr_sched.step()\n",
        "        \n",
        "    return train_losses, val_losses, valid_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc4fx-Ivw6Ok"
      },
      "source": [
        "def plot_trainig(train_losses, valid_losses, valid_accuracies):\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.plot(train_losses, label='train_loss')\n",
        "    plt.plot(valid_losses, label='valid_loss')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.plot(valid_accuracies, label='valid accuracy')\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co4YjJZHxSPc"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 5x5 image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dw1nGSYxZdc"
      },
      "source": [
        "model = Model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "info = fit(10, model, criterion, optimizer, *get_dataloaders(4))\n",
        "plot_trainig(*info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUXenYA1q16j"
      },
      "source": [
        "## Base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCT6ioLMq8q6"
      },
      "source": [
        "### Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqXiqTbJq4Vb"
      },
      "source": [
        "torch.HalfTensor      # 16 бит, floating point\n",
        "torch.FloatTensor     # 32 бита, floating point\n",
        "torch.DoubleTensor    # 64 бита, floating point\n",
        "\n",
        "torch.ShortTensor     # 16 бит, integer, signed\n",
        "torch.IntTensor       # 32 бита, integer, signed\n",
        "torch.LongTensor      # 64 бита, integer, signed\n",
        "\n",
        "torch.CharTensor      # 8 бит, integer, signed\n",
        "torch.ByteTensor      # 8 бит, integer, unsigned\n",
        "\n",
        "torch.FloatTensor([[1,2,3], [4,5,6]])\n",
        "torch.FloatTensor(2,3,4)\n",
        "torch.FloatTensor(3, 2, 4).zero_()\n",
        "\n",
        "a.type_as(torch.IntTensor())\n",
        "\n",
        "# np.reshape() == torch.view()\n",
        "b.view(3, 2)\n",
        "b.view(-1)\n",
        "\n",
        "a.sum(dim=0)\n",
        "a.sum(1)\n",
        "\n",
        "a.t()\n",
        "\n",
        "# вектор на вектор\n",
        "a.dot(b)\n",
        "a @ b\n",
        "\n",
        "# матрица на матрицу\n",
        "a.mm(b)\n",
        "a @ b\n",
        "\n",
        "# матрица на вектор\n",
        "a.mv(b)\n",
        "a @ b\n",
        "\n",
        "torch.from_numpy(a)\n",
        "x = a.numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-tGXm-iu3rH"
      },
      "source": [
        "### Cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi5saqVQu6EZ"
      },
      "source": [
        "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')\n",
        "\n",
        "x.is_cuda\n",
        "device = torch.device(\"cuda:0\")\n",
        "x = x.to(device)\n",
        "c = a.cuda().mul(b.cuda()).cpu()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')          # CUDA-device object\n",
        "    y = torch.ones_like(x, device=device)  # create a tensor on GPU\n",
        "    x = x.to(device)                       # or just `.to(\"cuda\")`\n",
        "    z = x + y\n",
        "    print(z.to(\"cpu\", torch.double))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgHs0TAkvdF3"
      },
      "source": [
        "### Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c7KrEW5veSY"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "N, D_in, H, D_out = 64, 3, 3, 10\n",
        "\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "y_pred = (x @ w1).clamp(min=0).mm(w2)\n",
        "\n",
        "loss = (y_pred - y).pow(2).sum()\n",
        "# calculate the gradients\n",
        "loss.backward()\n",
        "\n",
        "w1.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMlUP2bnynta"
      },
      "source": [
        "### Оптимизаторы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQptqPF8yz7h"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZtiEj1Ay-zJ"
      },
      "source": [
        "#### Регуляризация (WeightDecay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyg-sCuazsZw"
      },
      "source": [
        "Для регуляризации линейных моделей мы прибавляли к лоссу сумму квадратов весов, умноженных на некоторый коэффициент:\n",
        "$$L(\\mathbf{w})=\\sum_{i=1}^{l}\\left(\\mathbf{x}_{i}^{T} \\mathbf{w}-y_{i}\\right)^{2}+\\beta \\sum_{j=1}^{n} w_{j}^{2}$$\n",
        "\n",
        "Для нейронных сетей мы можем выбрать такую же реугляризацию. Она называется WeightDecay. Во многие оптимизаторы можно передать параметр `weight_decay` и он будет являться коэффициентом, на который домножается сумма квадратовв весов.\n",
        "\n",
        "Обычно используют weight_decay=0.01 или 0.005."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6567FWczyDw"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a-_Vrej0Nko"
      },
      "source": [
        "#### LR scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDfO7l5i0Xgl"
      },
      "source": [
        "Часто мы хотим, чтобы наш learning rate как-то изменялся во время обучения. Стратегия, по которой мы будем изменять lr называется lr scheduilng.\n",
        "\n",
        "Например, мы можем хотеть, чтобы learning_rate уменьшался с каждой эпохой в фиксированное число раз. Тогда в начале мы будем быстро двигаться к минимуму, а в конце точно не промахнемся мимо него за счет малых шагов. Такая стратегия называется LR Decay.\n",
        "![](https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/images/lr2.png)\n",
        "\n",
        "(Слева используется lr decay, справа нет. Слева мы можем не подбирать идеально точно lr и все равно со временем сойтись.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pShDrPG00RO2"
      },
      "source": [
        "my_optim = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=0.01)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC5SdYNH3HW6"
      },
      "source": [
        "### BatchNorm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWntjkHg6ks3"
      },
      "source": [
        "class ModelBatchNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelBatchNorm, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.bn1 = nn.BatchNorm2d(6)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 5x5 image dimension\n",
        "        self.bn3 = nn.BatchNorm1d(120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.max_pool2d(F.relu(self.conv1(x)), (2, 2)))\n",
        "        x = self.bn2(F.max_pool2d(F.relu(self.conv2(x)), 2))\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.bn3(F.relu(self.fc1(x)))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbnU0SAI3fka"
      },
      "source": [
        "```BatchNorm, математика```\n",
        "\n",
        "Если коротко, то BatchNorm для каждого признака вычитает среднее значение по батчу и делит на стандартное отклонение по батчу, потом домножает все признаки на вес $\\gamma$ и прибавляет вес $\\beta$. При этом возникает вопрос, что если мы используем модель уже для предсказаний и можем запускать ее только на одном примере.\n",
        "\n",
        "BatchNorm работает по разному во время обучения и предсказний:\n",
        "\n",
        "\n",
        "**Во время обучения**. Пусть батч состоит из $\\mathbf{x_i}$ (каждый $\\mathbf{x_i}$ - вектор, подающийся на вход). Тогда\n",
        "$$\\begin{aligned}\n",
        "\\mu_{\\mathcal{B}} & \\leftarrow \\frac{1}{m} \\sum_{i=1}^{m} x_{i} \\\\\n",
        "\\sigma_{\\mathcal{B}}^{2} & \\leftarrow \\frac{1}{m} \\sum_{i=1}^{m}\\left(x_{i}-\\mu_{\\mathcal{B}}\\right)^{2} \\\\\n",
        "\\widehat{x}_{i} & \\leftarrow \\frac{x_{i}-\\mu_{\\mathcal{B}}}{\\sqrt{\\sigma_{\\mathcal{B}}^{2}+\\epsilon}} \\\\\n",
        "y_{i} & \\leftarrow \\gamma \\widehat{x}_{i}+\\beta \\equiv \\mathrm{B} \\mathrm{N}_{\\gamma, \\beta}\\left(x_{i}\\right)\n",
        "\\end{aligned}$$\n",
        "\n",
        "**Во время предсказания**. Мы делаем то же самое, но у нас нет батча. Поэтому в качестве $\\mu_{\\mathcal{B}}$ и $\\sigma_{\\mathcal{B}}$ мы используем среднее и стандартное отклонение признака во всем датасете. Обычно нам не хочется после обучения еще раз применять сеть ко всем примерам из обучающего датасета, чтобы вычислить эти статистики и мы вместо них используем экспоненциально затухающее среднее последних батчей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFJ_gEcz6JvL"
      },
      "source": [
        "```BatchNorm, что он дает?```\n",
        "\n",
        "* Более быстрое обучение. Болшие learning_rate\"ы.\n",
        "* Обучение более глубоких сетей.\n",
        "* Регуляризация.\n",
        "* Повышение точности моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSUhKgpg6R7b"
      },
      "source": [
        "```BatchNorm для Conv слоев```\n",
        "\n",
        "Для сверточных слоев мы хотим следующее свойство \"если в разных частях картинки находятся одинаковые наборы пикселей, то соответствующие выходы сверточного слоя будут одинаковыми\". Если бы мы применяли алгоритм, который описан выше, то получилось бы так, что для пикселей, находящихся в 1 канале в координате (1,1) среднее и стд могли бы получиться не такими же как для пикселя в 1 канале в координате (10, 10). Тогда даже если изначально в них были одинаковые значения, то после BatchNorm они стали бы разными. \n",
        "\n",
        "Есть простое решение проблемы. Мы будем усреднять не только по batch_size координате, но и height, width координатам. Чтобы лучше объяснить используем псевдокод (origin https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network):\n",
        "\n",
        "На вход подается тензор (многомерный массив) размера [B, H, W, C]. Где B - количество батчей, H - высота картинок, W - ширина картинок, а C - количество каналов. Тогда обычный батчнорм выполнял бы нормирование так:\n",
        "```python\n",
        "# t is the incoming tensor of shape [B, H, W, C]\n",
        "# mean and stddev are computed along 0 axis and have shape [H, W, C]\n",
        "mean = mean(t, axis=0)\n",
        "stddev = stddev(t, axis=0)\n",
        "for i in 0..B-1:\n",
        "  out[i,:,:,:] = norm(t[i,:,:,:], mean, stddev)\n",
        "```\n",
        "\n",
        "В то время как батчнорм для сверточных сетей (BatchNorm2D в PyTorch):\n",
        "\n",
        "```python\n",
        "# t is still the incoming tensor of shape [B, H, W, C]\n",
        "# but mean and stddev are computed along (0, 1, 2) axes and have just [C] shape\n",
        "mean = mean(t, axis=(0, 1, 2))\n",
        "stddev = stddev(t, axis=(0, 1, 2))\n",
        "for i in 0..B-1, x in 0..H-1, y in 0..W-1:\n",
        "  out[i,x,y,:] = norm(t[i,x,y,:], mean, stddev)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxtq8Unr6diL"
      },
      "source": [
        "```BatchNorm, порядок применения```\n",
        "\n",
        "В оригинальной статье (http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43442.pdf) для сверточных слоев батчнорм предлагают использовать сразу после свертки до активации. Я не смог найти статей, которые бы исследовали, нужно ли делать BN до или после активации, и, похоже, однозначного мнения нет + в более сложных архитектурах (ResNet\"ы) исследователи обычно экспериментируют и ставят BN в разные места."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFh4o5s8mDlI"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "Дропаут это еще один необычный слой, который используется в нейронных сетях. У него есть один гиперпараметр $p$.\n",
        "\n",
        "Идея дропаута состоит в том, что во время обучения мы зануляем случайную часть входа и отдаем вход дальше (для каждого числа мы подбрасываем монетку и с вероятностью $p$ зануляем это число). \n",
        "\n",
        "Дропаут позволяет тренировать более устойчивые сети и избегать переобучения. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHAgRfpcmDlL"
      },
      "source": [
        "class ModelDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelDropout, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 5x5 image dimension\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk_UeJG1mDlJ"
      },
      "source": [
        "```Dropout, механика работы.```\n",
        "\n",
        "Как мы сказали выше, dropout зануляет случайную часть входов и отдает их дальше. Допустим $p=0.5$ (достаточное популярное значение). Тогда мы просто убираем половину всего входа! Такое сильное воздействие явно плохо повлияет на качество нашей модели, поэтому мы делаем зануление только во время обучения.\n",
        "\n",
        "**Во время обучения**: для каждого числа во входе подбрасываем монетку и зануляем его с вероятностью $p$. Выход умножаем на $\\frac{1}{1-p}$, чтобы дисперсия выходов осталось такой же, как и на входе.\n",
        "\n",
        "**Во время предсказаний**: ничего не делаем)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEjBjfinmDlJ"
      },
      "source": [
        "```Dropout, что дает?```\n",
        "\n",
        "* Сеть выучивает более устойчивые представления на внутренних слоях.\n",
        "* Сильно увеличивает число итераций, которые нужны для сходимости.\n",
        "* Можно получить интерпретацию, которая говорит, что дропаут усредняет выходы большо числа нейросетей с $p|W|$ нейронами на предыдущем слоев. \n",
        "\n",
        "Дропаут вызывает интересный эффект: в начале обучения качество на тестовом датасете выше, чем на обучающем. Потому что для обучающего датасета у нас есть зануление, которое сильно портит предсказания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzGtNEXlmDlK"
      },
      "source": [
        "```Dropout, взаимодействие с BatchNorm.```\n",
        "\n",
        "Статья, исследующая, почему исопльзование дропаута и батчнорма вместе часто ведет к более плохим результатам, чем их использование по-отдельности - https://arxiv.org/pdf/1801.05134.pdf\n",
        "\n",
        "(Если совсем коротко, то при наличии дропаута во время обучения и во время предсказаний выходы дропаута имеют разное распределение. Поэтому статистики, которые batchnorm считает для применения во время предсказаний, оказываются неверными.)\n",
        "\n",
        "Решение: если вы хотите использовать батчнорм и дропаут в одной сети, то все Dropout\"ы должны идти после BatchNorm\"ов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG_QDH1smDlK"
      },
      "source": [
        "```Dropout, PyTorch```\n",
        "\n",
        "В PyTorch есть `F.dropout(x, p=p)` и слой `nn.Dropout(p=p)`. В чем их отличие? `F.dropout(x, p=p)` не будет изменять свое поведение в заивимости от того, в каком стостянии сейчас модель (train, eval).\n",
        "\n",
        "Теперь чуть подробнее:\n",
        "\n",
        "Когда вы вызываете model.train()/model.eval() PyTorch проходится по всем переменным класса и если видит там наследника nn.Module или nn.ModuleList, то также меняет состояние для всех найденных модулей. Т.е. версия со слоем будет автоматически работать с train/eval состяниями. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMQz9o5ZwiVj"
      },
      "source": [
        "## Подготовка набора данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdeGObbfv-_n"
      },
      "source": [
        "В PyTorch датасетом считается любой объект, для которого определены методы `__len__(self)` и `__getitem__(self, i)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBwv3ocmv8UV"
      },
      "source": [
        "#### Compose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "809-sKKAv_bW"
      },
      "source": [
        "import torchvision.transforms as tfs\n",
        "\n",
        "data_tfs = tfs.Compose([\n",
        "  tfs.ToTensor(),\n",
        "  tfs.Normalize((0.5), (0.5))\n",
        "])\n",
        "\n",
        "root = './'\n",
        "train = MNIST(root, train=True,  transform=data_tfs, download=True)\n",
        "test  = MNIST(root, train=False, transform=data_tfs, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0uhh5Y0mdXQ"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "root = './'\n",
        "train = torchvision.datasets.CIFAR10(root, train=True,  transform=transform, download=True)\n",
        "test  = torchvision.datasets.CIFAR10(root, train=False, transform=transform, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f3CdTGpwTbs"
      },
      "source": [
        "#### DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn59qH6swU6l"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "x_batch, y_batch = next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIJvUt_COQ0Q"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlOGw7rq7Tqu"
      },
      "source": [
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ttsy_FciTjA"
      },
      "source": [
        "# Сами данные лежат в полях trainloader.dataset.train_data:\n",
        "trainloader.dataset.train_data.shape\n",
        "\n",
        "#Выведем первую картинку:\n",
        "numpy_img = trainloader.dataset.train_data[0].numpy()\n",
        "plt.imshow(numpy_img, cmap='gray');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TTYU1cZjIzf"
      },
      "source": [
        "# Как итерироваться по данным с помощью loader'а\n",
        "for data in trainloader:\n",
        "    print(data)\n",
        "    break\n",
        "# То есть мы имеем дело с кусочками данных размера batch_size (в данном случае = 4),\n",
        "# причём в каждом батче есть как объекты, так и ответы на них (то есть и X, и y)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzGCg_0AxnIq"
      },
      "source": [
        "## Model and Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAXlNKU2rvPY"
      },
      "source": [
        "### Цикл обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnw0FNgruNzT"
      },
      "source": [
        "код ниже подойдет для 90% задач"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJNFUUpUruSq"
      },
      "source": [
        "for epoch in range(max_epochs):  # <--------------- итерируемся по датасету несколько раз\n",
        "    for k, dataloader in loaders.items():  # <----- несколько dataloader для train / valid / test\n",
        "        for x_batch, y_batch in dataloader:  # <--- итерируемся по датасету. Так как мы используем SGD а не GD, то берем батчи заданного размера\n",
        "            if k == \"train\":\n",
        "                model.train()  # <------------------ переводим модель в режим train\n",
        "                optimizer.zero_grad()  # <--------- обнуляем градиенты модели\n",
        "                outp = model(x_batch)\n",
        "                loss = criterion(outp, y_batch) # <-считаем \"лосс\" для логистической регрессии\n",
        "                loss.backward()  # <--------------- считаем градиенты\n",
        "                optimizer.step()  # <-------------- делаем шаг градиентного спуска\n",
        "            else:  # <----------------------------- test/eval\n",
        "                model.eval()  # <------------------ переводим модель в режим eval\n",
        "                with torch.no_grad():  # <--------- НЕ считаем градиенты\n",
        "                    outp = model(x_batch)  # <------------- получаем \"логиты\" из модели\n",
        "            count_metrics(outp, y_batch)  # <-------------- считаем метрики"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwjkDNoLWAFN"
      },
      "source": [
        "### В ручную"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgnUAVE9xoyL"
      },
      "source": [
        "features = 784\n",
        "classes = 10\n",
        "epochs = 3\n",
        "lr=1e-2\n",
        "history = []\n",
        "\n",
        "W = torch.FloatTensor(features, classes).uniform_(-1, 1) / features**0.5\n",
        "\n",
        "for i in range(epochs):\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    x_batch = x_batch.reshape(x_batch.shape[0], -1)\n",
        "\n",
        "    logits = x_batch @ W\n",
        "    probabilities = torch.exp(logits) / torch.exp(logits).sum(dim=1, keepdims=True)\n",
        "    \n",
        "    loss = -torch.log(probabilities[range(batch_size), y_batch]).mean()\n",
        "    history.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    grad = W.grad\n",
        "    with torch.no_grad():\n",
        "      W -= lr * grad\n",
        "    W.grad.zero_()\n",
        "\n",
        "  print(f'{i+1},\\t loss: {history[-1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mni6AQ1UIJ_"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc = 0\n",
        "batches = 0\n",
        "\n",
        "for x_batch, y_batch in test_loader:\n",
        "  batches += 1\n",
        "  x_batch = x_batch.view(x_batch.shape[0], -1)\n",
        "  y_batch = y_batch\n",
        "\n",
        "  preds = torch.argmax(x_batch @ W, dim=1)\n",
        "  acc += (preds==y_batch).cpu().numpy().mean()\n",
        "\n",
        "print(f'Test accuracy {acc / batches:.3}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD61Babfu3rp"
      },
      "source": [
        "Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5T0Feonu9Zx"
      },
      "source": [
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(in_features, out_features, requires_grad=True))\n",
        "        self.bias = bias\n",
        "        if bias:\n",
        "            self.bias_term = nn.Parameter(torch.randn(1, out_features, requires_grad=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x =  x @ self.weights\n",
        "        if self.bias:\n",
        "            x +=  self.bias_term\n",
        "        return x\n",
        "\n",
        "X, y = make_moons(n_samples=10000, random_state=42, noise=0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)\n",
        "\n",
        "X_train_t =  torch.from_numpy(X_train).type_as(torch.FloatTensor())\n",
        "y_train_t =  torch.from_numpy(y_train).type_as(torch.FloatTensor())\n",
        "X_val_t =  torch.from_numpy(X_val).type_as(torch.FloatTensor())\n",
        "y_val_t =  torch.from_numpy(y_val).type_as(torch.FloatTensor())\n",
        "\n",
        "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
        "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=128)\n",
        "\n",
        "utils.set_global_seed(42)\n",
        "linear_regression = LinearRegression(2, 1)\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(linear_regression.parameters(), lr=0.05)\n",
        "\n",
        "tol = 1e-3\n",
        "losses = []\n",
        "max_epochs = 100\n",
        "prev_weights = torch.zeros_like(linear_regression.weights)\n",
        "stop_it = False\n",
        "for epoch in range(max_epochs):\n",
        "    utils.set_global_seed(42 + epoch)\n",
        "    for it, (X_batch, y_batch) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outp =  linear_regression(X_batch)\n",
        "        prob = F.sigmoid(outp)\n",
        "        loss =  -torch.log(torch.cat((prob[y_batch == 1], 1-prob[y_batch == 0]), 0)).mean()\n",
        "        loss.backward()\n",
        "        losses.append(loss.detach().flatten()[0])\n",
        "        optimizer.step()\n",
        "        probabilities =  prob\n",
        "        preds = (probabilities>0.5).type(torch.long)\n",
        "        batch_acc = (preds.flatten() == y_batch).type(torch.float32).sum()/y_batch.size(0)\n",
        "        if it % 500000 == 0:\n",
        "            print(f\"Iteration: {it + epoch*len(train_dataset)}\\nBatch accuracy: {batch_acc}\")\n",
        "        current_weights = linear_regression.weights.detach().clone()\n",
        "        if (prev_weights - current_weights).abs().max() < tol:\n",
        "            print(f\"\\nIteration: {it + epoch*len(train_dataset)}.Convergence. Stopping iterations.\")\n",
        "            stop_it = True\n",
        "            break\n",
        "        prev_weights = current_weights\n",
        "    if stop_it:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmeVrWr7WT6U"
      },
      "source": [
        "### nn.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEfS6aJNWkKt"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPbym84yWriF"
      },
      "source": [
        "model = nn.Sequential(\n",
        "  nn.Linear(features, 64),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(64, classes)\n",
        ")\n",
        "\n",
        "summary(model, (features,), batch_size=228)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # (logsoftmax + negative likelihood) in its core, applied to logits\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
        "\n",
        "epochs = 3\n",
        "history = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  for x_batch, y_batch in train_loader:\n",
        "    x_batch = x_batch.view(x_batch.shape[0], -1).to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "\n",
        "    loss = criterion(logits, y_batch)\n",
        "    history.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'{i+1},\\t loss: {history[-1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs5G1jghj-Ot"
      },
      "source": [
        "### Functional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfijZRrOkQlM"
      },
      "source": [
        "import torch.nn.functional as F  # Functional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqOZCvxwkVSs"
      },
      "source": [
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора предка\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 1),\n",
        "        # которую будем подавать в сеть, больше ничего\n",
        "        # про входящие картинки знать не нужно\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 16, 120)  # !!!\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 4 * 4 * 16)  # !!!\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHEkPdSEkmIs"
      },
      "source": [
        "**Важное примечание:** Вы можете заметить, что в строчках с `#!!!` есть не очень понятный сходу 4 `*` 4 `*` 16. Это -- размерность картинки перед FC-слоями (H x W x C), тут её приходиться высчитывать вручную (в Keras, например, `.Flatten()` всё делает за Вас). Однако есть один *лайфхак* -- просто сделайте в `forward()` `print(x.shape)` (закомментированная строка). Вы увидите размер `(batch_size, C, H, W)` -- нужно перемножить все, кроме первого (batch_size), это и будет первая размерность `Linear()`, и именно в C * H * W нужно \"развернуть\" x перед подачей в `Linear()`.  \n",
        "\n",
        "То есть нужно будет запустить цикл с обучением первый раз с `print()` и сделать после него `break`, посчитать размер, вписать его в нужные места и стереть `print()` и `break`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uwjgZxYk0rK"
      },
      "source": [
        "# Код обучения слоя:\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "# объявляем сеть\n",
        "net = SimpleConvNet().to(device)\n",
        "\n",
        "# выбираем функцию потерь\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# выбираем алгоритм оптимизации и learning_rate\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "losses = []\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "# итерируемся\n",
        "for epoch in tqdm_notebook(range(2)):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, batch in enumerate(tqdm_notebook(trainloader)):\n",
        "        # так получаем текущий батч\n",
        "        X_batch, y_batch = batch\n",
        "        \n",
        "        # обнуляем веса\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        y_pred = net(X_batch.to(device))\n",
        "        loss = loss_fn(y_pred, y_batch.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выведем текущий loss\n",
        "        running_loss += loss.item()\n",
        "        # выведем качество каждые 2000 батчей\n",
        "        if i % 2000 == 1999:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            losses.append(running_loss)\n",
        "            running_loss = 0.0\n",
        "\n",
        "    ax.clear()\n",
        "    ax.plot(np.arange(len(losses)), losses)\n",
        "    plt.show()\n",
        "\n",
        "print('Обучение закончено')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qvzJ37FlqcS"
      },
      "source": [
        "# Протестируем на всём тестовом датасете, используя метрику accuracy_score:\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        y_pred = net(images.to(device))\n",
        "        _, predicted = torch.max(y_pred, 1)\n",
        "        \n",
        "        c = (predicted.cpu().detach() == labels)\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWOtL4ZcipV1"
      },
      "source": [
        "### MyModule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ4RI2xbnu01"
      },
      "source": [
        "Что такое модуль и как он устроен? Во-первых, модуль это такой строительный блок для нейронок, с помощью модуля можно задать любую дифференциируемую по своему параметру функцию. Применяются модули так же, как и обычные функции с синтаксисом\n",
        "> module_instance(var1, var2)\n",
        "\n",
        "При этом внутри вызывается функция forward с теми же аргументами, а ее выход возвращается как результат вызова модуля. Зачем же нужно так странно оборачивать обычные функции в модули? \n",
        "\n",
        "* Это позволяет очень удобно следить за параметрами, которые надо изменять. Когда мы хоти получить все параметры можно просто рекурсивно пройтись по всем полям модели, посмотреть, какие из ни параметры сами по себе, а какие являются модулями и содрежат параметры внутри, а потом все это собрать. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHISAoqrn_3c"
      },
      "source": [
        "_По этой причине если вы используете внутри своего модуля какие-то еще модули их надо класть просто в поле класса, если это единичный модуль, и в класс **nn.ModuleList** или **nn.ModuleDict**, если у вас список или словарь используемых модулей. Если же в модели у вас есть како-то собственный вес, то недостаточно положить тензор в поле класса, его надо обернуть в **nn.Parameter, nn.ParameterList** или **nn.ParameterDict** в зависимотси от того, что именно у вас._\n",
        "\n",
        "* Такая организация позволяет достаточно безболезненно расширять PyTorch и писать для него свои функции, которые нельзя выразить композицией уже существующих. Пригождается это редко, поэтому сегодня мы не будем писать свое расширение.\n",
        "\n",
        "* Код, разделенный на модули, это просто красиво."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgRzlKJtiuXq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "class MyModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear_layers = nn.ModuleList([nn.Linear(D_in, H), nn.Linear(H, D_out)])\n",
        "        self.my_useless_bias = nn.Parameter(torch.ones(1, H, requires_grad=True))\n",
        "        self.more_of_my_useless_biases = nn.ParameterList([\n",
        "            nn.Parameter(torch.ones(1, H, requires_grad=True)),\n",
        "            nn.Parameter(torch.ones(1, H, requires_grad=True)),\n",
        "            nn.Parameter(torch.ones(1, H, requires_grad=True))\n",
        "        ])\n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.linear_layers[0](X))\n",
        "        X += self.my_useless_bias\n",
        "        for b in self.more_of_my_useless_biases:\n",
        "            X += b\n",
        "        return F.softmax(self.linear_layers[1](X))\n",
        "    \n",
        "model = MyModule()\n",
        "list(model.parameters())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j5k6ADrnHOv"
      },
      "source": [
        "class MyConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора предка\n",
        "        super().__init__()\n",
        "        # необходмо заранее знать, сколько каналов у картинки (сейчас = 1),\n",
        "        # которую будем подавать в сеть, больше ничего\n",
        "        # про входящие картинки знать не нужно\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.fc1 = nn.Linear(6 * 6 * 128, 128)  # !!!\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #(32,32)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        #(14,14)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #(6,6)\n",
        "        #print(x.shape)\n",
        "        x = x.view(-1, 6 * 6 * 128)  # !!!\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}